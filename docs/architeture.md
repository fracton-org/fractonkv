# 1. Architecture Overview

## Core Idea

This project is a **multi-threaded reactive key-value store** written in Rust.
The goal is to combine **performance** (shard-per-thread model, no locking), **modularity** (protocol adapters like TCP,
HTTP, gRPC), and **reactivity** (subscriptions & streaming updates) in one clean design.

Think of it as:

* **A Redis-like store** but with explicit sharding and job queues.
* **Multi-protocol** from the start (TCP â†’ HTTP â†’ gRPC â†’ WebSockets).
* **Future extensibility** for scripting, reactivity, and custom modules.

---

## High-Level Design

### Shards

* Data is **split across shards**.
* Each shard is **owned by one Tokio worker thread**.
* **No locks needed** â†’ one thread owns its shardâ€™s memory.
* Communication with a shard is done by **pushing jobs to its job queue**.

### Job Queue

* Each shard has a **queue of jobs (commands)**.
* Jobs are **scheduled onto shards** based on the key being accessed (hashing).
* Shard executes jobs **sequentially** (single-threaded execution â†’ no race conditions).

### Protocol Layer

* Clients can connect via **TCP (initial)**.
* Future support: **HTTP, gRPC, WebSockets, Protobufs**.
* Protocol layer **parses incoming requests into commands**, and hands them to the shard job queue.

### Command Execution

* Commands like `GET`, `SET`, `DEL` are **dispatched to shards**.
* Shard executes command and **returns result** via a response channel.

### Reactivity (Future Phase)

* Clients can **subscribe** to keys or patterns.
* Whenever a key is updated, subscribers get **pushed updates**.
* Useful for streaming or cache invalidation.

### Scripting (Future Phase)

* Support running **user-defined scripts** (Lua/JS).
* Scripts can read/write data from inside shard context.
* Ensures scripts are **sandboxed** and donâ€™t break isolation.

---

## ASCII Architecture Diagram

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚       Client Apps       â”‚
         â”‚ (TCP, HTTP, gRPC, etc.) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              Protocol Layer
    (parsers, serialization, request routing)
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Job Dispatcher     â”‚
          â”‚ (hash key â†’ shard)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚              â”‚              â”‚
 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
 â”‚ Shard 1  â”‚   â”‚ Shard 2  â”‚   â”‚ Shard N  â”‚
 â”‚ (Thread) â”‚   â”‚ (Thread) â”‚   â”‚ (Thread) â”‚
 â”‚ Job Q    â”‚   â”‚ Job Q    â”‚   â”‚ Job Q    â”‚
 â”‚ Data     â”‚   â”‚ Data     â”‚   â”‚ Data     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ­ Design Patterns

* **Actor Model** â†’ Each shard acts like an actor: owns its state, communicates via messages.
* **Message Passing** â†’ `tokio::mpsc` channels connect the router â†” shards.
* **Traits for Extensibility** â†’ Define clear interfaces for persistence, logging, replication.
* **Separation of Concerns** â†’ Networking â‰  Routing â‰  Storage â‰  Extensions.

---

## âš ï¸ Pitfalls to Avoid

1. **Response ordering**

    * Make sure router preserves per-connection command order, even with async shard replies.

2. **Backpressure**

    * Use bounded `mpsc` channels to avoid unbounded memory growth under load.

3. **Shard imbalance**

    * Consistent hashing works well, but hot keys may overload one shard â†’ consider rebalancing strategies in the
      future.

4. **Extensibility creep**

    * Keep logging/persistence hooks modular â€” donâ€™t bake them into shard logic directly.

---
